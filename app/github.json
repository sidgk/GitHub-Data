{
  "sha": "e08125cb62646bb43f1c0651fd3ff608412f5e21",
  "node_id": "MDY6Q29tbWl0ODkyNjY3MzU6ZTA4MTI1Y2I2MjY0NmJiNDNmMWMwNjUxZmQzZmY2MDg0MTJmNWUyMQ==",
  "commit": {
    "author": {
      "name": "Nathan Shuster",
      "email": "nshuster8@gmail.com",
      "date": "2020-08-28T22:10:24Z"
    },
    "committer": {
      "name": "GitHub",
      "email": "noreply@github.com",
      "date": "2020-08-28T22:10:24Z"
    },
    "message": "Add new HRED agent and integration tests (#2989)\n\n* Add HRED agent that extends seq2seq\r\n\r\n* added integration unit tests and broke hred out into it's own module\r\n\r\n* removed old seq2seq hred, removed some unsupported functionality\r\n\r\n* Add FB blurb and update to use new models that were trained on PyTorch 1.4\r\n\r\n* add __init__ to agent and add a short train test to test_hred\r\n\r\n* give test an extra 2 epochs of leeway and add a README for hred\r\n\r\n* ran autoformat and removed bad input test\r\n\r\nCo-authored-by: nshuster <nshuster@devvm316.ash0.facebook.com>",
    "tree": {
      "sha": "21b4e78d09364e21c12c1b895dedf0cdc78176f0",
      "url": "https://api.github.com/repos/facebookresearch/ParlAI/git/trees/21b4e78d09364e21c12c1b895dedf0cdc78176f0"
    },
    "url": "https://api.github.com/repos/facebookresearch/ParlAI/git/commits/e08125cb62646bb43f1c0651fd3ff608412f5e21",
    "comment_count": 0,
    "verification": {
      "verified": true,
      "reason": "valid",
      "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfSYDQCRBK7hj4Ov3rIwAAdHIIABHYcf85qJaS+Z+V6+ZdxpfG\nohMYUcYqNAeQiDBXy8/45xRSi+ifCm5B/7dWXA2ZD/PBjKfxwJX3ESOZT1YF5JJV\n4hpGjZMYVKPIKiWOaKgZBC7zupl4bHjzUgMp3AwOpEuJoIZP6ZI6gzE3GzERkCp+\ne8Aab+fNlURkEqa5FHi+NVtd4LrlZlB7aBdeMJuufONWd1ee3b26iFn4+SeT/NZX\nWcY15nxz/1eecjoagOvkFTrg1rE9Y/LShOdohk68BOUqyadFGvg3Px200QhU6+oK\nvEdpF5AfxEjPkohCgl5Dc6ey/QRUNeHDhz1osywLn2DRdw1boyzqMZgE5mqIE7Q=\n=QSHt\n-----END PGP SIGNATURE-----\n",
      "payload": "tree 21b4e78d09364e21c12c1b895dedf0cdc78176f0\nparent 25ccce589598a53734af99c150469c69c23ab772\nauthor Nathan Shuster <nshuster8@gmail.com> 1598652624 -0400\ncommitter GitHub <noreply@github.com> 1598652624 -0400\n\nAdd new HRED agent and integration tests (#2989)\n\n* Add HRED agent that extends seq2seq\r\n\r\n* added integration unit tests and broke hred out into it's own module\r\n\r\n* removed old seq2seq hred, removed some unsupported functionality\r\n\r\n* Add FB blurb and update to use new models that were trained on PyTorch 1.4\r\n\r\n* add __init__ to agent and add a short train test to test_hred\r\n\r\n* give test an extra 2 epochs of leeway and add a README for hred\r\n\r\n* ran autoformat and removed bad input test\r\n\r\nCo-authored-by: nshuster <nshuster@devvm316.ash0.facebook.com>"
    }
  },
  "url": "https://api.github.com/repos/facebookresearch/ParlAI/commits/e08125cb62646bb43f1c0651fd3ff608412f5e21",
  "html_url": "https://github.com/facebookresearch/ParlAI/commit/e08125cb62646bb43f1c0651fd3ff608412f5e21",
  "comments_url": "https://api.github.com/repos/facebookresearch/ParlAI/commits/e08125cb62646bb43f1c0651fd3ff608412f5e21/comments",
  "author": {
    "login": "NathanShuster",
    "id": 22328456,
    "node_id": "MDQ6VXNlcjIyMzI4NDU2",
    "avatar_url": "https://avatars2.githubusercontent.com/u/22328456?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/NathanShuster",
    "html_url": "https://github.com/NathanShuster",
    "followers_url": "https://api.github.com/users/NathanShuster/followers",
    "following_url": "https://api.github.com/users/NathanShuster/following{/other_user}",
    "gists_url": "https://api.github.com/users/NathanShuster/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/NathanShuster/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/NathanShuster/subscriptions",
    "organizations_url": "https://api.github.com/users/NathanShuster/orgs",
    "repos_url": "https://api.github.com/users/NathanShuster/repos",
    "events_url": "https://api.github.com/users/NathanShuster/events{/privacy}",
    "received_events_url": "https://api.github.com/users/NathanShuster/received_events",
    "type": "User",
    "site_admin": false
  },
  "committer": {
    "login": "web-flow",
    "id": 19864447,
    "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
    "avatar_url": "https://avatars3.githubusercontent.com/u/19864447?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/web-flow",
    "html_url": "https://github.com/web-flow",
    "followers_url": "https://api.github.com/users/web-flow/followers",
    "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
    "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
    "organizations_url": "https://api.github.com/users/web-flow/orgs",
    "repos_url": "https://api.github.com/users/web-flow/repos",
    "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
    "received_events_url": "https://api.github.com/users/web-flow/received_events",
    "type": "User",
    "site_admin": false
  },
  "parents": [
    {
      "sha": "25ccce589598a53734af99c150469c69c23ab772",
      "url": "https://api.github.com/repos/facebookresearch/ParlAI/commits/25ccce589598a53734af99c150469c69c23ab772",
      "html_url": "https://github.com/facebookresearch/ParlAI/commit/25ccce589598a53734af99c150469c69c23ab772"
    }
  ],
  "stats": {
    "total": 598,
    "additions": 597,
    "deletions": 1
  },
  "files": [
    {
      "sha": "147b440aaaf5971eab2f8eb6c58ac3c429290151",
      "filename": "parlai/agents/hred/README.md",
      "status": "added",
      "additions": 13,
      "deletions": 0,
      "changes": 13,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/README.md",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/README.md",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/parlai/agents/hred/README.md?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -0,0 +1,13 @@\n+# HRED Agent\n+The HRED agent uses a traditional LSTM encoder decoder, but also utilizes a context LSTM that encodes the history.\n+\n+The following papers outline more information regarding this model:\n+  - Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models [(IV Serban et al. 2015)](https://arxiv.org/abs/1507.04808)\n+  - A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues\n+    [(IV Serban et al. 2017)](http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf)\n+\n+An important difference is that the model currently only supports LSTM RNN units, rather than the GRU units used in the papers. It also supports the decoding strategies in TorchGeneratorModel (such as beam search and greedy).\n+\n+Example script to run on dailydialog:\n+parlai train_model -t dailydialog -mf /tmp/dailydialog_hred -bs 4 -eps 5 --model hred\n+"
    },
    {
      "sha": "240697e32479afeb085e35a5a3327723db4d8a37",
      "filename": "parlai/agents/hred/__init__.py",
      "status": "added",
      "additions": 5,
      "deletions": 0,
      "changes": 5,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/__init__.py",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/__init__.py",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/parlai/agents/hred/__init__.py?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -0,0 +1,5 @@\n+#!/usr/bin/env python3\n+\n+# Copyright (c) Facebook, Inc. and its affiliates.\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree."
    },
    {
      "sha": "630e17d84f57616bc0799f983ec97e68f35bdcc2",
      "filename": "parlai/agents/hred/hred.py",
      "status": "added",
      "additions": 188,
      "deletions": 0,
      "changes": 188,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/hred.py",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/hred.py",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/parlai/agents/hred/hred.py?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -0,0 +1,188 @@\n+#!/usr/bin/env python3\n+\n+# Copyright (c) Facebook, Inc. and its affiliates.\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree.\n+\n+import torch\n+from parlai.agents.seq2seq.modules import opt_to_kwargs\n+from parlai.core.torch_generator_agent import TorchGeneratorAgent\n+\n+from .modules import HredModel\n+\n+\n+class HredAgent(TorchGeneratorAgent):\n+    @classmethod\n+    def add_cmdline_args(cls, argparser):\n+        \"\"\"\n+        Add command-line arguments specifically for this agent.\n+        \"\"\"\n+        agent = argparser.add_argument_group(\"HRED Arguments\")\n+        agent.add_argument(\n+            \"-hs\",\n+            \"--hiddensize\",\n+            type=int,\n+            default=128,\n+            help=\"size of the hidden layers\",\n+        )\n+        agent.add_argument(\n+            \"-esz\",\n+            \"--embeddingsize\",\n+            type=int,\n+            default=128,\n+            help=\"size of the token embeddings\",\n+        )\n+        agent.add_argument(\n+            \"-nl\", \"--numlayers\", type=int, default=2, help=\"number of hidden layers\"\n+        )\n+        agent.add_argument(\n+            \"-dr\", \"--dropout\", type=float, default=0.1, help=\"dropout rate\"\n+        )\n+        agent.add_argument(\n+            \"-lt\",\n+            \"--lookuptable\",\n+            default=\"unique\",\n+            choices=[\"unique\", \"enc_dec\", \"dec_out\", \"all\"],\n+            help=\"The encoder, decoder, and output modules can \"\n+            \"share weights, or not. \"\n+            \"Unique has independent embeddings for each. \"\n+            \"Enc_dec shares the embedding for the encoder \"\n+            \"and decoder. \"\n+            \"Dec_out shares decoder embedding and output \"\n+            \"weights. \"\n+            \"All shares all three weights.\",\n+        )\n+        agent.add_argument(\n+            \"-idr\",\n+            \"--input-dropout\",\n+            type=float,\n+            default=0.0,\n+            help=\"Probability of replacing tokens with UNK in training.\",\n+        )\n+\n+        super(HredAgent, cls).add_cmdline_args(argparser)\n+        return agent\n+\n+    def __init__(self, opt, shared=None):\n+        \"\"\"\n+        Set up model.\n+        \"\"\"\n+        if torch.cuda.is_available():\n+            self.device = torch.device(\"cuda:0\")\n+        else:\n+            self.device = torch.device(\"cpu\")\n+        super().__init__(opt, shared)\n+        self.id = \"Hred\"\n+\n+    def build_model(self, states=None):\n+        opt = self.opt\n+        if not states:\n+            states = {}\n+        kwargs = opt_to_kwargs(opt)\n+\n+        model = HredModel(\n+            len(self.dict),\n+            opt[\"embeddingsize\"],\n+            opt[\"hiddensize\"],\n+            device=self.device,\n+            padding_idx=self.NULL_IDX,\n+            start_idx=self.START_IDX,\n+            end_idx=self.END_IDX,\n+            unknown_idx=self.dict[self.dict.unk_token],\n+            longest_label=states.get(\"longest_label\", 1),\n+            **kwargs,\n+        )\n+\n+        if opt.get(\"dict_tokenizer\") == \"bpe\" and opt[\"embedding_type\"] != \"random\":\n+            print(\"skipping preinitialization of embeddings for bpe\")\n+        elif not states and opt[\"embedding_type\"] != \"random\":\n+            # `not states`: only set up embeddings if not loading model\n+            self._copy_embeddings(model.decoder.lt.weight, opt[\"embedding_type\"])\n+            if opt[\"lookuptable\"] in [\"unique\", \"dec_out\"]:\n+                # also set encoder lt, since it's not shared\n+                self._copy_embeddings(\n+                    model.encoder.lt.weight, opt[\"embedding_type\"], log=False\n+                )\n+\n+        if states:\n+            # set loaded states if applicable\n+            model.load_state_dict(states[\"model\"])\n+\n+        if opt[\"embedding_type\"].endswith(\"fixed\"):\n+            print(\"Seq2seq: fixing embedding weights.\")\n+            model.decoder.lt.weight.requires_grad = False\n+            model.encoder.lt.weight.requires_grad = False\n+            if opt[\"lookuptable\"] in [\"dec_out\", \"all\"]:\n+                model.output.weight.requires_grad = False\n+\n+        return model\n+\n+    def batchify(self, obs_batch, sort=True):\n+        \"\"\"\n+        Add action and attribute supervision for batches.\n+\n+        Store history vec as context_vec.\n+        \"\"\"\n+        batch = super().batchify(obs_batch, sort)\n+        batch[\"context_vec\"], batch[\"hist_lens\"] = self.parse_context_vec(batch)\n+        return batch\n+\n+    def parse_context_vec(self, batch):\n+        batch_context_vec = []\n+        hist_lens = []\n+        for i in range(len(batch[\"observations\"])):\n+            hist_len = len(batch[\"observations\"][i][\"context_vec\"])\n+            hist_lens.append(hist_len)\n+            for j in range(hist_len):\n+                context_vec = batch[\"observations\"][i][\"context_vec\"][j]\n+                batch_context_vec.append(torch.tensor(context_vec, device=self.device))\n+\n+        padded_context_vec = torch.nn.utils.rnn.pad_sequence(\n+            batch_context_vec, batch_first=True\n+        ).squeeze(1)\n+        return (\n+            padded_context_vec,\n+            torch.tensor(hist_lens, dtype=torch.long, device=self.device),\n+        )\n+\n+    def _model_input(self, batch):\n+        return (batch.text_vec, batch.context_vec, batch.hist_lens)\n+\n+    def _set_text_vec(self, obs, history, truncate):\n+        \"\"\"\n+        Set the 'text_vec' field in the observation.\n+\n+        Overridden to include both local utterance (text_vec) and full history\n+        (context_vec)\n+        \"\"\"\n+        if \"text\" not in obs:\n+            return obs\n+\n+        if \"text_vec\" not in obs:\n+            # text vec is not precomputed, so we set it using the history\n+            history_string = history.get_history_str()\n+            # when text not exist, we get text_vec from history string\n+            # history could be none if it is an image task and 'text'\n+            # filed is be empty. We don't want this\n+            if history_string is None:\n+                return obs\n+            obs[\"full_text\"] = history_string\n+            if history_string:\n+                history_vec = history.get_history_vec_list()\n+                obs[\"text_vec\"] = history_vec[-1]\n+                obs[\"context_vec\"] = history_vec\n+\n+        # check truncation\n+        if obs.get(\"text_vec\") is not None:\n+            truncated_vec = self._check_truncate(obs[\"text_vec\"], truncate, True)\n+            obs.force_set(\"text_vec\", torch.LongTensor(truncated_vec))\n+        return obs\n+\n+    def _dummy_batch(self, batchsize, maxlen):\n+        \"\"\"\n+        Overridden to add dummy context vec and hist lens.\n+        \"\"\"\n+        batch = super()._dummy_batch(batchsize, maxlen)\n+        batch[\"context_vec\"] = batch[\"text_vec\"]\n+        batch[\"hist_lens\"] = torch.ones(batchsize, dtype=torch.long)\n+        return batch"
    },
    {
      "sha": "ad4fbbb3d2a6d1d03e6cb42bb04d4eed621e7568",
      "filename": "parlai/agents/hred/modules.py",
      "status": "added",
      "additions": 305,
      "deletions": 0,
      "changes": 305,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/modules.py",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/agents/hred/modules.py",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/parlai/agents/hred/modules.py?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -0,0 +1,305 @@\n+#!/usr/bin/env python3\n+\n+# Copyright (c) Facebook, Inc. and its affiliates.\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree.\n+\n+import torch\n+import torch.nn as nn\n+from parlai.agents.seq2seq.modules import (\n+    OutputLayer,\n+    RNNEncoder,\n+    _transpose_hidden_state,\n+)\n+from parlai.core.torch_generator_agent import TorchGeneratorModel\n+\n+\n+class HredModel(TorchGeneratorModel):\n+    \"\"\"\n+    HRED model that has a context LSTM layer.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        num_features,\n+        embeddingsize,\n+        hiddensize,\n+        device,\n+        numlayers=2,\n+        dropout=0,\n+        bidirectional=False,\n+        rnn_class=\"lstm\",\n+        lookuptable=\"unique\",\n+        decoder=\"same\",\n+        numsoftmax=1,\n+        attention=\"none\",\n+        attention_length=48,\n+        attention_time=\"post\",\n+        padding_idx=0,\n+        start_idx=1,\n+        end_idx=2,\n+        unknown_idx=3,\n+        input_dropout=0,\n+        longest_label=1,\n+    ):\n+\n+        super().__init__(\n+            padding_idx=padding_idx,\n+            start_idx=start_idx,\n+            end_idx=end_idx,\n+            unknown_idx=unknown_idx,\n+            input_dropout=input_dropout,\n+            longest_label=longest_label,\n+        )\n+\n+        rnn_class = nn.LSTM\n+        embedding_size = embeddingsize\n+        hidden_size = hiddensize\n+\n+        self.encoder = HredEncoder(\n+            num_features=num_features,\n+            embeddingsize=embedding_size,\n+            hiddensize=hidden_size,\n+            rnn_class=rnn_class,\n+            numlayers=numlayers,\n+            device=device,\n+        )\n+\n+        self.decoder = HredDecoder(\n+            num_features=num_features,\n+            embeddingsize=embedding_size,\n+            hiddensize=hidden_size,\n+            rnn_class=rnn_class,\n+            numlayers=numlayers,\n+        )\n+\n+        self.output = OutputLayer(\n+            num_features=num_features,\n+            embeddingsize=embedding_size,\n+            hiddensize=hidden_size,\n+        )\n+\n+    def reorder_encoder_states(self, encoder_states, indices):\n+        \"\"\"\n+        Reorder encoder states according to a new set of indices.\n+        \"\"\"\n+        enc_out, hidden, attn_mask, context_vec = encoder_states\n+        # make sure we swap the hidden state around, apropos multigpu settings\n+        hidden = _transpose_hidden_state(hidden)\n+\n+        # LSTM or GRU/RNN hidden state?\n+        if isinstance(hidden, torch.Tensor):\n+            hid, cell = hidden, None\n+        else:\n+            hid, cell = hidden\n+\n+        if not torch.is_tensor(indices):\n+            # cast indices to a tensor if needed\n+            indices = torch.LongTensor(indices).to(hid.device)\n+\n+        hid = hid.index_select(1, indices)\n+        if cell is None:\n+            hidden = hid\n+        else:\n+            cell = cell.index_select(1, indices)\n+            hidden = (hid, cell)\n+\n+        # and bring it back to multigpu friendliness\n+        hidden = _transpose_hidden_state(hidden)\n+        context_vec = context_vec.index_select(0, indices)\n+        return enc_out, hidden, attn_mask, context_vec\n+\n+    def reorder_decoder_incremental_state(self, incremental_state, inds):\n+        if torch.is_tensor(incremental_state):\n+            # gru or vanilla rnn\n+            return torch.index_select(incremental_state, 0, inds).contiguous()\n+        elif isinstance(incremental_state, tuple):\n+            return tuple(\n+                self.reorder_decoder_incremental_state(x, inds)\n+                for x in incremental_state\n+            )\n+\n+\n+class HredEncoder(RNNEncoder):\n+    \"\"\"\n+    RNN Encoder.\n+\n+    Modified to encode history vector in context lstm.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        num_features,\n+        embeddingsize,\n+        hiddensize,\n+        device,\n+        padding_idx=0,\n+        rnn_class=\"lstm\",\n+        numlayers=2,\n+        dropout=0.1,\n+        bidirectional=False,\n+        shared_lt=None,\n+        shared_rnn=None,\n+        input_dropout=0,\n+        unknown_idx=None,\n+        sparse=False,\n+    ):\n+        \"\"\"\n+        Initialize recurrent encoder and context lstm.\n+        \"\"\"\n+        super().__init__(\n+            num_features,\n+            embeddingsize,\n+            hiddensize,\n+            padding_idx,\n+            rnn_class,\n+            numlayers,\n+            dropout,\n+            bidirectional,\n+            shared_lt,\n+            shared_rnn,\n+            input_dropout,\n+            unknown_idx,\n+            sparse,\n+        )\n+        self.padding_idx = padding_idx\n+        self.context_lstm = nn.LSTM(\n+            hiddensize, hiddensize, numlayers, batch_first=True\n+        ).to(device)\n+\n+    def forward(self, xs, context_vec, hist_lens):\n+        # encode current utterrance\n+        (enc_state, (hidden_state, cell_state), attn_mask) = super().forward(xs)\n+        # if all utterances in context vec length 1, unsqueeze to prevent loss of dimensionality\n+        if len(context_vec.shape) < 2:\n+            context_vec = context_vec.unsqueeze(1)\n+        # get utt lengths of each utt in context vector\n+        utt_lens = torch.sum(context_vec.ne(0).int(), dim=1)\n+        # sort by lengths descending for utterance encoder\n+        sorted_lens, sorted_idx = utt_lens.sort(descending=True)\n+        sorted_context_vec = context_vec[sorted_idx]\n+        (_, (sorted_hidden_state, _), _) = super().forward(sorted_context_vec)\n+        sorted_final_hidden_states = sorted_hidden_state[:, -1, :]\n+\n+        ### reshape and pad hidden states to bsz x max_hist_len x hidden_size using hist_lens\n+        original_order_final_hidden = torch.zeros_like(\n+            sorted_final_hidden_states\n+        ).scatter_(\n+            0,\n+            sorted_idx.unsqueeze(1).expand(-1, sorted_final_hidden_states.shape[1]),\n+            sorted_final_hidden_states,\n+        )\n+        # pad to max hist_len\n+        original_size_final_hidden = self.sequence_to_padding(\n+            original_order_final_hidden, hist_lens\n+        )\n+        # pack padded sequence so that we ignore padding\n+        original_size_final_hidden_packed = nn.utils.rnn.pack_padded_sequence(\n+            original_size_final_hidden,\n+            hist_lens.cpu(),\n+            batch_first=True,\n+            enforce_sorted=False,\n+        )\n+        # pass through context lstm\n+        _, (context_h_n, _) = self.context_lstm(original_size_final_hidden_packed)\n+        return (\n+            enc_state,\n+            (hidden_state, cell_state),\n+            attn_mask,\n+            _transpose_hidden_state(context_h_n),\n+        )\n+\n+    def sequence_to_padding(self, x, lengths):\n+        \"\"\"\n+        Return padded and reshaped sequence (x) according to tensor lengths\n+        Example:\n+            x = tensor([[1, 2], [2, 3], [4, 0], [5, 6], [7, 8], [9, 10]])\n+            lengths = tensor([1, 2, 2, 1])\n+        Would output:\n+            tensor([[[1, 2], [0, 0]],\n+                    [[2, 3], [4, 0]],\n+                    [[5, 6], [7, 8]],\n+                    [[9, 10], [0, 0]]])\n+        \"\"\"\n+        ret_tensor = torch.zeros(\n+            (lengths.shape[0], torch.max(lengths).int()) + tuple(x.shape[1:])\n+        ).to(x.device)\n+        cum_len = 0\n+        for i, l in enumerate(lengths):\n+            ret_tensor[i, :l] = x[cum_len : cum_len + l]\n+            cum_len += l\n+        return ret_tensor\n+\n+\n+class HredDecoder(nn.Module):\n+    \"\"\"\n+    Recurrent decoder module that uses dialog history encoded by context lstm.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        num_features,\n+        embeddingsize,\n+        hiddensize,\n+        padding_idx=0,\n+        rnn_class=\"lstm\",\n+        numlayers=2,\n+        dropout=0.1,\n+        bidir_input=False,\n+        attn_length=-1,\n+        sparse=False,\n+    ):\n+        \"\"\"\n+        Initialize recurrent decoder.\n+        \"\"\"\n+        super().__init__()\n+        self.dropout = nn.Dropout(p=dropout)\n+        self.layers = numlayers\n+        self.hsz = hiddensize\n+        self.esz = embeddingsize\n+\n+        self.lt = nn.Embedding(\n+            num_features, embeddingsize, padding_idx=padding_idx, sparse=sparse\n+        )\n+        self.rnn = rnn_class(\n+            embeddingsize + hiddensize,\n+            hiddensize,\n+            numlayers,\n+            dropout=dropout if numlayers > 1 else 0,\n+            batch_first=True,\n+        )\n+\n+    def forward(self, xs, encoder_output, incremental_state=None):\n+        \"\"\"\n+        Decode from input tokens.\n+\n+        :param xs: (bsz x seqlen) LongTensor of input token indices\n+        :param encoder_output: output from HredEncoder. Tuple containing\n+            (enc_out, enc_hidden, attn_mask, context_hidden) tuple.\n+        :param incremental_state: most recent hidden state to the decoder.\n+        :returns: (output, hidden_state) pair from the RNN.\n+            - output is a bsz x time x latentdim matrix. This value must be passed to\n+                the model's OutputLayer for a final softmax.\n+            - hidden_state depends on the choice of RNN\n+        \"\"\"\n+        (\n+            enc_state,\n+            (hidden_state, cell_state),\n+            attn_mask,\n+            context_hidden,\n+        ) = encoder_output\n+\n+        # sequence indices => sequence embeddings\n+        seqlen = xs.size(1)\n+        xes = self.dropout(self.lt(xs))\n+\n+        # concatentate context lstm hidden state\n+        context_hidden_final_layer = context_hidden[:, -1, :].unsqueeze(1)\n+        resized_context_h = context_hidden_final_layer.expand(-1, seqlen, -1)\n+        xes = torch.cat((xes, resized_context_h), dim=-1).to(xes.device)\n+\n+        # run through rnn with None as initial decoder state\n+        # source for zeroes hidden state: http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf\n+        output, new_hidden = self.rnn(xes, None)\n+\n+        return output, _transpose_hidden_state(new_hidden)"
    },
    {
      "sha": "930a9f67226090c8f4f886e5845825337c8156c0",
      "filename": "parlai/zoo/unittest/build.py",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/zoo/unittest/build.py",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/parlai/zoo/unittest/build.py",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/parlai/zoo/unittest/build.py?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -16,7 +16,7 @@ def download(datapath):\n     opt = {'datapath': datapath}\n     model_name = 'unittest'\n     mdir = os.path.join(get_model_dir(datapath), model_name)\n-    version = 'v6.1'\n+    version = 'v7.1'\n     model_filenames = [\n         'seq2seq.tar.gz',\n         'transformer_ranker.tar.gz',\n@@ -26,6 +26,7 @@ def download(datapath):\n         'test_bytelevel_bpe_v2.tar.gz',\n         'beam_blocking1.tar.gz',\n         'context_blocking1.tar.gz',\n+        'hred_model_v1.tar.gz',\n     ]\n     if not built(mdir, version):\n         download_models(opt, model_filenames, model_name, version=version)"
    },
    {
      "sha": "1a5ea01cdd73d7db47ab59f2b3654ffad41df6e7",
      "filename": "tests/test_hred.py",
      "status": "added",
      "additions": 84,
      "deletions": 0,
      "changes": 84,
      "blob_url": "https://github.com/facebookresearch/ParlAI/blob/e08125cb62646bb43f1c0651fd3ff608412f5e21/tests/test_hred.py",
      "raw_url": "https://github.com/facebookresearch/ParlAI/raw/e08125cb62646bb43f1c0651fd3ff608412f5e21/tests/test_hred.py",
      "contents_url": "https://api.github.com/repos/facebookresearch/ParlAI/contents/tests/test_hred.py?ref=e08125cb62646bb43f1c0651fd3ff608412f5e21",
      "patch": "@@ -0,0 +1,84 @@\n+#!/usr/bin/env python3\n+\n+# Copyright (c) Facebook, Inc. and its affiliates.\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree.\n+\n+import unittest\n+\n+import parlai.utils.testing as testing_utils\n+\n+\n+BATCH_SIZE = 8\n+\n+\n+class TestHred(unittest.TestCase):\n+    \"\"\"\n+    Checks that Hred can learn some very basic tasks.\n+    \"\"\"\n+\n+    def test_generation(self):\n+        valid, test = testing_utils.train_model(\n+            dict(\n+                task=\"integration_tests:multiturn_candidate\",\n+                model=\"hred\",\n+                batchsize=BATCH_SIZE,\n+                num_epochs=10,\n+                embeddingsize=16,\n+                hiddensize=32,\n+                numlayers=1,\n+                dropout=0.0,\n+                skip_generation=True,\n+            )\n+        )\n+        self.assertLess(valid[\"ppl\"], 2)\n+\n+    @testing_utils.retry(ntries=3)\n+    def test_greedy(self):\n+        \"\"\"\n+        Test a simple multiturn task.\n+        \"\"\"\n+        valid, test = testing_utils.eval_model(\n+            dict(\n+                task=\"integration_tests:multiturn_candidate\",\n+                model=\"hred\",\n+                model_file=\"zoo:unittest/hred_model/model\",\n+                dict_file=\"zoo:unittest/hred_model/model.dict\",\n+                skip_generation=False,\n+                inference=\"greedy\",\n+                numlayers=1,\n+                embeddingsize=16,\n+                hiddensize=32,\n+                batchsize=BATCH_SIZE,\n+            )\n+        )\n+\n+        self.assertLess(valid[\"ppl\"], 1.2)\n+        self.assertLess(test[\"ppl\"], 1.2)\n+\n+    @testing_utils.retry(ntries=3)\n+    def test_beamsearch(self):\n+        \"\"\"\n+        Ensures beam search can generate the correct response.\n+        \"\"\"\n+        valid, test = testing_utils.eval_model(\n+            dict(\n+                task=\"integration_tests:multiturn_candidate\",\n+                model=\"hred\",\n+                model_file=\"zoo:unittest/hred_model/model\",\n+                dict_file=\"zoo:unittest/hred_model/model.dict\",\n+                skip_generation=False,\n+                numlayers=1,\n+                embeddingsize=16,\n+                hiddensize=32,\n+                batchsize=8,\n+                inference=\"beam\",\n+                beam_size=5,\n+            )\n+        )\n+        self.assertGreater(valid[\"accuracy\"], 0.95)\n+        self.assertGreater(test[\"accuracy\"], 0.95)\n+\n+\n+if __name__ == \"__main__\":\n+    unittest.main()"
    }
  ]
}